{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "61d183dc-0a1d-4959-8638-35aade4a440f",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "source": [
    "## General Root Finding Algorithms\n",
    "\n",
    "To use Newton's method, we need to know the derivative $f'(x)$.  However, sometimes we don't know (or don't want to evaluate) $f'(x)$.  In that case, we could try approximating $f'(x)$ by \n",
    "\n",
    "$$\n",
    "f'(p_i)\\approx \\frac{f(p_i)-f(p_{i-1})}{p_i-p_{i-1}}.\n",
    "$$\n",
    "\n",
    "If we are close enough the to root to get convergence, as $i\\rightarrow \\infty$ then $p_{i-1}\\rightarrow p_i$ so that this expression should approach the true derivative at $f'(p_i)$.  This gives us\n",
    "\n",
    "> **Secant Method**: Given $p_0$ and $p_1$ then\n",
    ">\n",
    "> $$ p_{i+1}=p_i -\\frac{f(p_i)}{\\left[\\frac{f(p_i)-f(p_{i-1})}{p_i-p_{i-1}}\\right]},\\qquad i=1,2,3,\\cdots $$\n",
    "\n",
    "There is a cost in doing this in that i) we need two initial guesses and ii) the rate of convergence turns out to be $\\alpha \\approx 1.618$ which is less than the quadratic convergence of Newton's method but still much better than linear convergence.\n",
    "\n",
    "It is also reasonable to ask: Can we do better?  The secant method can also be derived from fitting a line to the points $(p_{i-1},f(p_{i-1}))$ and $(p_{i},f(p_{i}))$ and finding where that line crosses zero.  Once we have three guesses, we could fit a quadratic polynomial through the three points.  There are actually two choices here, as illustrated in the following sketch:\n",
    "\n",
    "<img src=\"./img/QuadraticRoot.png\" width=\"750\">\n",
    "\n",
    "In [Müller's method](https://en.wikipedia.org/wiki/Muller%27s_method), illustrated in the left panel above, one uses the previous three points to construct the quadratic polynomial $P(x)=a(x-p_{i})^2+b(x-p_{i})+c$ (we will discuss how to find an interpolating polynomial going through three points in a later chapter).  One then uses the quadratic formula to find the roots of $P(x)$ and then picks one of those, usually the closest to $p_{i}$ as the next guess $p_{i+1}$.  In addition to the issue that we need to select one of two roots, there is also the possibility that both roots could be complex.  If we are looking for complex roots this is not a problem, but otherwise we are stuck unless we continue the iterations using complex number arithmetic.  As a result, Müller's method's is primarily used only in the context of finding complex roots. \n",
    "\n",
    "Our alternative, namely [Inverse Quadratic Interpolation](https://en.wikipedia.org/wiki/Inverse_quadratic_interpolation) (IQI), instead constructs a quadratic polynomial $x=P(y)=a y^2+b y+c$ from the previous three iterates.  This parabola will intersect the x-axis at a single real-numbered point (just plug in $y=0$).  It turns out that IQI has rate of convergence $\\alpha\\approx 1.8$, so note quite as good a Newton's method, but better than the Secant method.\n",
    "\n",
    "The secant, or quadratic methods relieve us of the issue of needing to compute a derivative of our function, but they don't change the requirement that we need to start in a neighborhood of the root in order to converge.  This is compounded by the fact that we don't actualy know the size of the neighborhood *a priori*.  There are several hybrid methods that combine different schemes we have discussed to provide the certainty of Bisection with the speed of a superlinear method.  The most popular of these is **Brent's Method** which follows the following scheme given in pseudocode:"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d81e220a-c39f-4b31-9bcf-ae31e4325040",
   "metadata": {},
   "source": [
    "**Brent's Method**\n",
    "\n",
    "<code>\n",
    "1. Bracket root of f(x) on some interval [a,b]\n",
    "2. Try secant method to get p<sub>3</sub>, using a=p<sub>1</sub> and b=p<sub>2</sub>\n",
    "   If (|f(p<sub>3</sub>| < |f(a)|) AND (|f(p<sub>3</sub>| < |f(a)|) AND (min(|a-p<sub>3</sub>|,|b-p<sub>3</sub>|) < |b-a|/2)\n",
    "   then \n",
    "       accept p<sub>3</sub> and replace a or b with p<sub>3</sub> keeping root bracketed in [a,b]\n",
    "   else use bisection to find p<sub>3</sub>\n",
    "3. for i=3 to max iteration\n",
    "       Try IQI on last 3 iterates to generate p<sub>i+1</sub>\n",
    "       If (|f(p<sub>i+1</sub>| < |f(p<sub>i</sub>)|) AND (min(|a-p<sub>i+1</sub>|,|b-p<sub>i+1</sub>|) < |b-a|/2)\n",
    "       then \n",
    "           accept p<sub>i+1</sub> and replace a or b with p<sub>i+1</sub> keeping root bracketed in [a,b]\n",
    "       else \n",
    "           Try secant method with the same test\n",
    "           If test fails, use bisection\n",
    "</code>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8ebcedce-ec10-4820-a788-b6f5774c31fc",
   "metadata": {},
   "source": [
    "SciPy has an implementation of Brent's method, `brentq`, in its Optimization and Root finding submodule.  You must bracket the root yourself before calling though.  \n",
    "\n",
    "**Example:** Let's use Brent's method to find the root of the function $f(x)=e^{-x}\\cos{x}$ that we previously bracketed in the interval $[1,2]$ in the Bisection section."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "f6ce1ac9-38d6-451f-9146-7c53bd921581",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best guess for root is 1.57079632679499\n",
      "\n",
      "Again with full output:\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(1.57079632679499,\n",
       "       converged: True\n",
       "            flag: converged\n",
       "  function_calls: 10\n",
       "      iterations: 9\n",
       "            root: 1.57079632679499\n",
       "          method: brentq)"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import numpy as np\n",
    "def my_f(x):\n",
    "    return np.exp(-x)*np.cos(x)\n",
    "\n",
    "from scipy import optimize\n",
    "\n",
    "root = optimize.brentq(my_f, 1, 2)\n",
    "print(f\"Best guess for root is {root}\\n\")\n",
    "\n",
    "print(\"Again with full output:\")\n",
    "optimize.brentq(my_f, 1, 2, full_output=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c42fd0c3-c5fb-4937-8072-0505f01094a4",
   "metadata": {},
   "source": [
    "We can also specify an absolute error test with optional parameter `xtol` or a relative error test with optional parameter `rtol`, or a mixed test by specifying both, as well as a maximum number of iterations as with our previous examples"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "8255dcf2-dfb8-4811-a8ea-6798a389a463",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best guess for root is 1.57079632679499\n",
      "\n"
     ]
    }
   ],
   "source": [
    "root = optimize.brentq(my_f, 1, 2, xtol=2e-12, rtol=8.9e-16, maxiter=100)\n",
    "print(f\"Best guess for root is {root}\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "afa9cb40-d826-44a4-a310-33b1afa2fece",
   "metadata": {},
   "source": [
    "In practise, Newton and Brent's method are the main root finding methods used.  \n",
    "\n",
    "An exception occurs when you have a root of [multiplicity](https://en.wikipedia.org/wiki/Multiplicity_(mathematics)#Multiplicity_of_a_root_of_a_polynomial) greater than one where Newton's method converges only linearly.  You can either accept the slower convergence or fix this by [modifying Newton's method](https://en.wikipedia.org/wiki/Newton's_method#Slow_convergence_for_roots_of_multiplicity_greater_than_1) however if you don't know the multiplicity of the root you will have the added cost of supplying not only the first but also the second derivative.\n",
    "\n",
    "Another exception is when you wish to find the roots of a polynomial.  In this case, you can take advantage of the special structure of the polynomial to construct an algorithm for finding not just one, but all of the polynomials roots.  An example of such an algorithm is [Laguerre's Method](https://en.wikipedia.org/wiki/Laguerre%27s_method) and [others](https://en.wikipedia.org/wiki/Polynomial_root-finding)."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "155f0fdc-5dca-4be8-b6bb-2bea5b91b601",
   "metadata": {},
   "source": [
    "All the methods in this chapter have focused on one-dimensional problems.  In many cases we need to find the solution to equations containing more than one variable.  To solve these, we need to first review solving linear systems of equations which is the subject of the next chapter."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b5cde93b-a011-4ab9-aca2-ad3b713fc26e",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.20"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
