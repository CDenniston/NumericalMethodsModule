{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "e6f9b1b0-87fc-4427-bd75-183f44f09643",
   "metadata": {},
   "source": [
    "### Gaussian Elimination with Back Subsitution\n",
    "\n",
    "We will assume here that you are familiar with concepts from linear algebra and in particular, Gaussian Elimination.  However, students often learn a variety of different techniques involving row reduction, such as reducing all the way to an identity matrix, or reducing until you have one on the diagonal elements.  While those all lead to the same solution mathematically, so involve a larger number of numerical floating point calculations than absolutely necessary.  Numerically this is disadvantages both from the performance (i.e. how long the algorithm takes) aspect as well as the fact that more floating point calculations introduce more possibilities to magnify roundoff error.  Here, we want to solve our system using the smallest number of floating point operations as illustrated in the following example.\n",
    "\n",
    "**Example:**  Consider the following set of equations we would like to solve:\n",
    "\n",
    "$$\n",
    "\\begin{align}\n",
    " {\\begin{array}{cccc}\n",
    "    E_1: & x_1+x_2+x_3+x_4     &=&3\\\\\n",
    "    E_2: & x_1+2x_2+4x_3+8x_4  &=&-2\\\\\n",
    "    E_3: & x_1+3x_2+9x_3+27x_4 &=&-5\\\\\n",
    "    E_4: & x_1+4x_2+16x_3+64x_n&=&0 \\\\\n",
    "  \\end{array}}\n",
    "\\end{align}\n",
    "$$\n",
    "\n",
    "which we can convert into the following augmented matrix\n",
    "\n",
    "$$\n",
    "\\begin{align}\n",
    "  \\left[ {\\begin{array}{cccc}\n",
    "     \\textcolor{red}{1} &  1 & 1 &  1 \\\\\n",
    "     1 &  2 & 4 &  8 \\\\\n",
    "     1 &  3 & 9 &  27 \\\\\n",
    "     1 &  4 & 16 &  64 \\\\\n",
    "  \\end{array} } \\right|\n",
    "  \\left. {{\\begin{array}{c}\n",
    "   3 \\\\\n",
    "  -2 \\\\\n",
    "  -5 \\\\\n",
    "  0 \\\\\n",
    "  \\end{array}}} \\right] = A^{(1)} \n",
    "\\end{align}\n",
    "$$\n",
    "\n",
    "We refer to the element in red as the *pivot* element.  We will use the ratio of the first element in each row to the pivot element, something we will call a *multiplier* to determine what multiple of row 1 (or equation 1, $E_1$) to add to each row to reduce all the elements below the pivot to zero.  Adding a multiple of one row to another does not change our solution, just moves us towards a more easily solvable system:\n",
    "\n",
    "$$\n",
    "\\begin{align}\n",
    " {\\begin{array}{cc}\n",
    " E_1 &:\\\\\n",
    " (E_2-(\\frac{1}{\\textcolor{red}{1}})E_1)\\rightarrow E_2 &: \\\\\n",
    " (E_3-(\\frac{1}{\\textcolor{red}{1}})E_1)\\rightarrow E_3 &: \\\\\n",
    " (E_4-(\\frac{1}{\\textcolor{red}{1}})E_1)\\rightarrow E_4 &: \\\\\n",
    " \\end{array}}\\qquad\n",
    "  \\left[ {\\begin{array}{cccc}\n",
    "     1 &  1 & 1 &  1 \\\\\n",
    "     0 &  \\textcolor{red}{1} & 3 &  7 \\\\\n",
    "     0 &  2 & 8 &  26 \\\\\n",
    "     0 &  3 & 15 &  63 \\\\\n",
    "  \\end{array} } \\right|\n",
    "  \\left. {{\\begin{array}{c}\n",
    "   3 \\\\\n",
    "  -5 \\\\\n",
    "  -8 \\\\\n",
    "  -3 \\\\\n",
    "  \\end{array}}} \\right] = A^{(2)} \n",
    "\\end{align}\n",
    "$$\n",
    "\n",
    "We now move on the lower right block that excludes the first row and column and repeat the procedure.  Using the pivot element (again indicated in red above) to determine what multiple of row 2 ($E_2$) to add to each subsequent row to reduce all the elements below the pivot to zero:\n",
    "\n",
    "$$\n",
    "\\begin{align}\n",
    " {\\begin{array}{cc}\n",
    " E_1 & :\\\\\n",
    " E_2 & :\\\\\n",
    " (E_3-(\\frac{2}{\\textcolor{red}{1}})E_2)\\rightarrow E_3 &:\\\\\n",
    " (E_4-(\\frac{3}{\\textcolor{red}{1}})E_2)\\rightarrow E_4 &:\\\\\n",
    " \\end{array}}\\qquad\n",
    "  \\left[ {\\begin{array}{cccc}\n",
    "     1 &  1 & 1 &  1 \\\\\n",
    "     0 &  1 & 3 &  7 \\\\\n",
    "     0 &  0 & \\textcolor{red}{2} &  12 \\\\\n",
    "     0 &  0 & 6 &  42 \\\\\n",
    "  \\end{array} } \\right|\n",
    "  \\left. {{\\begin{array}{c}\n",
    "   3 \\\\\n",
    "  -5 \\\\\n",
    "  2 \\\\\n",
    "  12 \\\\\n",
    "  \\end{array}}} \\right] = A^{(3)} \n",
    "\\end{align}\n",
    "$$\n",
    "\n",
    "One final row reduction reduces the coefficient matrix to an *upper triangular matrix*:\n",
    "\n",
    "$$\n",
    "\\begin{align}\n",
    " {\\begin{array}{cc}\n",
    " E_1 & :\\\\\n",
    " E_2 & :\\\\\n",
    " E_3 & :\\\\\n",
    " (E_4-(\\frac{6}{\\textcolor{red}{2}})E_3)\\rightarrow E_4 &:\\\\\n",
    " \\end{array}}\\qquad\n",
    "  \\left[ {\\begin{array}{cccc}\n",
    "     1 &  1 & 1 &  1 \\\\\n",
    "     0 &  1 & 3 &  7 \\\\\n",
    "     0 &  0 & 2 &  12 \\\\\n",
    "     0 &  0 & 0 &  6 \\\\\n",
    "  \\end{array} } \\right|\n",
    "  \\left. {{\\begin{array}{c}\n",
    "   3 \\\\\n",
    "  -5 \\\\\n",
    "  2 \\\\\n",
    "  6 \\\\\n",
    "  \\end{array}}} \\right] = A^{(4)} \n",
    "\\end{align}\n",
    "$$\n",
    "\n",
    "Note that we do not care if the pivot element is not $1$.  It is never worthwhile to divide all the elements in a row to get the pivot to be one.  Doing so only increases the overall number of floating point operations necessary to solve the system.  Now that our system is in upper triangular form we stop, switch strategies and do **back substitution**: We start with the last equation which now involves only $x_4$ so is easily solved.  $E_3$ only involves $x_3$ and $x_4$, so now knowing $x_4$ it can be easily rearranged to solve for $x_3$.  We continue in this manner until we get up to the first equation:\n",
    "\n",
    "$$\n",
    "\\begin{align}\n",
    "x_4 &= 6/6 = 1\\\\\n",
    "x_3 &= (2-12x_4)/2 = -5\\\\\n",
    "x_2 &= (-5-7x_4-3x_3)/1 =3\\\\\n",
    "x_1 &= (3-x_4-x_3+x_2)/1 = 4\\\\\n",
    "\\end{align}\n",
    "$$\n",
    "\n",
    "The method used in the above example is referred to as *Gaussian Elimination with Back Substitution*.  To construct the algorithm, let's first focus on the *forward elimination* part and consider what we did to go from $A^{(1)}$ to $A^{(2)}$:\n",
    "\n",
    "$$ E_i - \\frac{a_{i1}}{a_{11}}E_1 \\rightarrow E_i,\\qquad\\qquad i=2,3,\\cdots,n $$\n",
    "\n",
    "or in pseudo-code form\n",
    "\n",
    "$$\n",
    "\\begin{align}\n",
    "    &\\text{// Loop over rows 2 to }\\,n\\\\\n",
    "    &\\text{for}\\,\\, i=2,\\cdots n\\\\\n",
    "    &\\qquad\\text{m}_{i1} = \\text{a}_{i1}/\\text{a}_{11}\\\\\n",
    "    &\\qquad\\text{// Loop over columns of row}\\,i\\\\\n",
    "    &\\qquad\\text{for}\\,\\, j=1,\\cdots n+1\\\\\n",
    "    &\\qquad\\qquad  \\text{a}_{ij}=\\text{a}_{ij}-\\text{m}_{i1}*\\text{a}_{1j}\n",
    "\\end{align}\n",
    "$$\n",
    "\n",
    "The full algorithm just requires applying the above to the successively smaller sub-blocks until we have reduced the coefficient matrix into lower triangular form.  Before translating this into a python code we must contend with the fact that while mathematics textbooks will typically label vectors and matrices of length $n$ with indices from $1$ to $n$, unless you are using a very old language like FORTRAN, most modern languages index arrays from $0$ to $n-1$.  This means that we must shift the matrix/vector indices in an algorithm by one to get the corresponding array index.\n",
    "\n",
    "One final point is that any element set to zero is never used again.  As such, we don't actually need to set it to zero.  In fact, for future reference we *could* store the multipliers used in the algorithm in the *lower triangular* part of the matrix that would otherwise be zero.  We will come back to why this is useful when we discuss matrix factorization.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "263b1657-6f96-44f0-8788-f096f2a44c35",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Initial Augmented Matrix:\n",
      " [[ 1.  1.  1.  1.  3.]\n",
      " [ 1.  2.  4.  8. -2.]\n",
      " [ 1.  3.  9. 27. -5.]\n",
      " [ 1.  4. 16. 64.  0.]]\n",
      "Row-reduced Augmented Matrix:\n",
      " [[ 1.  1.  1.  1.  3.]\n",
      " [ 0.  1.  3.  7. -5.]\n",
      " [ 0.  0.  2. 12.  2.]\n",
      " [ 0.  0.  0.  6.  6.]]\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "\n",
    "def ForwardElimination(A,n):\n",
    "    # row k contains our pivot\n",
    "    for k in range(0,n-1):\n",
    "        # our pivot is element A[k,k]\n",
    "        # Now we loop over i, the rows below the pivot row\n",
    "        for i in range(k+1,n):\n",
    "            m=A[i,k]/A[k,k]\n",
    "            # Loop over j, the columns of row i\n",
    "            # The line below is equivalent to the following loop,\n",
    "            # for j in range(k,n+1):\n",
    "            #    A[i,j] -= m*A[k,j]\n",
    "            A[i, k:] -= m*A[k, k:]\n",
    "    return\n",
    "\n",
    "AugmentedArray=np.array([[1,1,1,1,3],[1,2,4,8,-2],[1,3,9,27,-5],[1,4,16,64,0]],dtype=np.float64)\n",
    "print(\"Initial Augmented Matrix:\\n\", AugmentedArray)\n",
    "ForwardElimination(AugmentedArray,4)\n",
    "print(\"Row-reduced Augmented Matrix:\\n\", AugmentedArray)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f0bb3835-7969-4903-8656-3c6df06717cd",
   "metadata": {},
   "source": [
    "This agrees with our example so let's move on to the *Back Substitution* step.  Here we are solving equations like\n",
    "\n",
    "$$\n",
    "a_{kk}x_k+a_{k,k+1}x_{k+1}+\\cdots+a_{kn}x_n = a_{k,n+1}\n",
    "$$\n",
    "\n",
    "Keeping in mind that we already know $x_{k+1},\\cdots,x_n$ at this stage so\n",
    "\n",
    "$$\n",
    "x_k = \\left(a_{k,n+1}-\\sum_{j=k+1}^n a_{kj}x_j\\right)/a_{kk}\n",
    "$$\n",
    "\n",
    "Putting this together into a python routine, again noting the shift in indices by $1$ to account for indexing from $0$, gives"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "39b06519-ed7b-469d-94e9-7bcdb829a232",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ 4.  3. -5.  1.]\n"
     ]
    }
   ],
   "source": [
    "def BackSubstitution(A,n):\n",
    "    x=np.zeros(n)\n",
    "    x[n-1]=A[n-1,n]/A[n-1,n-1]\n",
    "    for k in range(n-2,-1, -1):\n",
    "        x[k]=A[k,n]\n",
    "        for j in range(k+1,n):\n",
    "            x[k] -= A[k,j]*x[j]\n",
    "        x[k]=x[k]/A[k,k]\n",
    "    return x\n",
    "\n",
    "my_x = BackSubstitution(AugmentedArray,4)\n",
    "print(my_x)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3c1fe1a2-0ba1-4d37-90e1-54ed6ebbe953",
   "metadata": {},
   "source": [
    "Which gives us back the solution from our example.  One point that should have given you some concern is that we divide by our pivot $a_{kk}$ in both Forward Elimination and the Backward Substitution routines.  The concern here is that it is not at all impossible that we may encounter a zero pivot elements (i.e. $a_{kk}=0$) which will cause the algorithm to fail as we cannot add a multiple of zero to another nonzero element and expect to reduce it to zero.  It turns out that the pivot does not even have to be zero for this to cause a problem.  A small pivot can also cause problems from roundoff effects.  It turns out this is fairly straighforwardly solved by introducing a *pivoting strategy*, which we will discuss in the next section."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.20"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
