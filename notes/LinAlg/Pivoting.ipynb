{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "e6f9b1b0-87fc-4427-bd75-183f44f09643",
   "metadata": {},
   "source": [
    "### Pivoting Strategies\n",
    "\n",
    "In our quest to solve a linear system of equations, we have not made use of the ability to swap rows so far.  If we encounter a zero pivot, we can swap rows to fix the problem.  If there is no non-zero pivot, then there is no unique solution and we can exit with an appropriate error message.  This suggests adding a *choose pivot* section to the Forward Elimination routine along the lines of \n",
    "\n",
    "$$\n",
    "\\begin{align}\n",
    "    &\\text{find}\\, p,\\, k\\leq p \\leq n,\\, \\text{such that}\\,\\text{a}_{pk}\\neq 0\\\\\n",
    "    &\\text{if this is not possible,}\\,A\\,\\text{is singular, so stop}\\\\\n",
    "    &E_p \\leftrightarrow E_k\\,\\text{if}\\,p\\neq k\\\\\n",
    "\\end{align}\n",
    "$$\n",
    "\n",
    "In reality, it is not actually a good idea to actually interchange rows as this memory swap takes some time and in later applications it will be useful to have a record of the swaps.  In python, a straightforward way to deal with this is to have a row index array that stores which row is which in the augmented matrix.  Then the row swap just consists of swapping the values in the row index and then use the row index array value in place of the row index anywhere else in the code. \n",
    "\n",
    "We also haven't quite tied down the find $\\text{a}_{pk}\\neq 0$ step.  There could easily be more than one value of $p$ for which this would be the case.  Which one should we pick?  We learned in the Errors in Scientific Computing chapter that dividing by a small number can magnify roundoff errors.  Given our multipliers are of the form $\\text{a}_{ik}/\\text{a}_{kk}$, if $\\text{a}_{kk}$ is small we could be agravating roundoff errors.  This suggests selecting the largest possible pivot in column $k$.  \n",
    "\n",
    "<img src=\"./image/PartialPivoting.png\" width=\"250\">\n",
    "\n",
    "This will also ensure that our multipliers are all less than or equal to 1. This strategy is called **partial pivoting** and is usually the default for most routines.  We can modify our earier Forward Elimination routine to include partial pivoting as shown below, returning our row index array.  We then must modify our Back Substitution routine to use the row index array as well.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "263b1657-6f96-44f0-8788-f096f2a44c35",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Initial Augmented Matrix:\n",
      " [[ 1.  1.  1.  1.  3.]\n",
      " [ 1.  2.  4.  8. -2.]\n",
      " [ 1.  3.  9. 27. -5.]\n",
      " [ 1.  4. 16. 64.  0.]]\n",
      "Row-reduced Augmented Matrix:\n",
      " [[  1.   1.   1.   1.   3.]\n",
      " [  0.   0.   0.   2.   2.]\n",
      " [  0.   0.  -2. -16.  -6.]\n",
      " [  0.   3.  15.  63.  -3.]]\n",
      "row index:\n",
      " [0 3 2 1]\n",
      "solution:\n",
      " [ 4.  3. -5.  1.]\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "\n",
    "def ForwardElimination(A,n):\n",
    "    # setup our row index array\n",
    "    nrows=np.array(range(0,n),dtype=int)\n",
    "    for k in range(0,n-1):\n",
    "        # select pivot element A[k,k]\n",
    "        pivot = A[nrows[k],k]\n",
    "        prow = nrows[k]\n",
    "        for p in range(k+1,n):\n",
    "            if (abs(A[nrows[p],k]) > abs(pivot)) :\n",
    "                prow = p\n",
    "        if (prow != nrows[k]) :\n",
    "            pivot = A[nrows[p],k]\n",
    "            if (pivot == 0) :\n",
    "                print(\"Singular Matrix Encountered\\n\")\n",
    "                return nrows\n",
    "            # As rows may have been swapped previously, we need to double index nrows\n",
    "            tmp = nrows[nrows[k]]\n",
    "            nrows[nrows[k]]=nrows[nrows[prow]]\n",
    "            nrows[nrows[prow]]=tmp\n",
    "        # Now we loop over i, the rows below the pivot row\n",
    "        for i in range(k+1,n):\n",
    "            m=A[nrows[i],k]/pivot\n",
    "            # Loop over j, the columns of row i\n",
    "            # The line below is equivalent to the following loop,\n",
    "            # for j in range(k,n+1):\n",
    "            #    A[i,j] -= m*A[k,j]\n",
    "            A[nrows[i], k:] -= m*A[nrows[k], k:]\n",
    "    return nrows\n",
    "\n",
    "def BackSubstitution(A,n,nrows):\n",
    "    x=np.zeros(n)\n",
    "    x[n-1]=A[nrows[n-1],n]/A[nrows[n-1],n-1]\n",
    "    for k in range(n-2,-1, -1):\n",
    "        x[k]=A[nrows[k],n]\n",
    "        for j in range(k+1,n):\n",
    "            x[k] -= A[nrows[k],j]*x[j]\n",
    "        x[k]=x[k]/A[nrows[k],k]\n",
    "    return x\n",
    "\n",
    "AugmentedArray=np.array([[1,1,1,1,3],[1,2,4,8,-2],[1,3,9,27,-5],[1,4,16,64,0]],dtype=np.float64)\n",
    "print(\"Initial Augmented Matrix:\\n\", AugmentedArray)\n",
    "rowsindx=ForwardElimination(AugmentedArray,4)\n",
    "print(\"Row-reduced Augmented Matrix:\\n\", AugmentedArray)\n",
    "print(\"row index:\\n\",rowsindx)\n",
    "\n",
    "my_x = BackSubstitution(AugmentedArray,4,rowsindx)\n",
    "print(\"solution:\\n\",my_x)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f0bb3835-7969-4903-8656-3c6df06717cd",
   "metadata": {},
   "source": [
    "We see that this gives the same solution as before, but it is evident that the path to get there was different.  Normally, but not always, partial pivoting works well.  To minimize roundoff errors further we could use a strategy called **total** or **complete** pivoting.  In this case, we switch rows *and* columns, choosing the pivot as the maximum element in the coefficient matrix in rows $k,\\cdots,n$ *and* columns $k,\\cdots n$.  \n",
    "\n",
    "<img src=\"./image/TotalPivoting.png\" width=\"250\">\n",
    "\n",
    "This restricts the growth in all elements in the coefficient block we are working as it is possible to show that\n",
    "\n",
    "$$\n",
    "|a_{ij}-m_{ik}a_{kj}|\\leq 2 \\max_{k\\leq i,j \\leq n} |a_{ij}|\n",
    "$$\n",
    "\n",
    "Total pivoting is an option in LAPACK routines and is only done when absolutely necessary.  Why?  This is related to the cost of doing so, but to discuss that we first need to discuss the cost for the algorithm so far."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3c1fe1a2-0ba1-4d37-90e1-54ed6ebbe953",
   "metadata": {},
   "source": [
    "Which gives us back the solution from our example.  One point that should have given you some concern is that we divide by our pivot $a_{kk}$ in both Forward Elimination and the Backward Substitution routines.  The concern here is that it is not at all impossible that we may encounter a zero pivot elements (i.e. $a_{kk}=0$) which will cause the algorithm to fail as we cannot add a multiple of zero to another nonzero element and expect to reduce it to zero.  It turns out that the pivot does not even have to be zero for this to cause a problem.  A small pivot can also cause problems from roundoff effects.  It turns out this is fairly straighforwardly solved by introducing a *pivoting strategy*, which we will discuss in the next."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b5fa7190-4043-4b4e-800f-970910c57194",
   "metadata": {},
   "source": [
    "## Computational Cost\n",
    "\n",
    "To evaluate the cost, we count the number of *flops*, or floating point operations (one addition plus one multiplication, so computing $a+bx$ is 1 flop).  Some summation formulas from first year Calculus that will be useful in this computation.  We will focus on the case where $n$ is very large.\n",
    "\n",
    "````{dropdown} **Summation Formulas** \n",
    " \n",
    "$$\n",
    "\\sum_{k=1}^n 1 = n \\\\\n",
    "$$\n",
    "\n",
    "$$\n",
    "\\sum_{k=1}^n k = \\frac{n(n+1)}{2} \\approx \\frac{n^2}{2}\n",
    "$$\n",
    "\n",
    "$$\n",
    "\\sum_{k=1}^n k^2= \\frac{n(n+1)(2n+1)}{6} \\approx \\frac{n^3}{3}\n",
    "$$\n",
    "\n",
    "````\n",
    "\n",
    "The work of forward elimination is mostly the repeated executions of the last line of innermost loop, where each individual operation is 1 flop.  As noted in the comment in the algorithm, that line is effectively part of a loop, and each loop further up results in a repition of this inner loop.  We just need to count each iteration of this operation, with each loop contributing a summation sign.   Which gives us\n",
    "\n",
    "$$\n",
    "\\begin{align}\n",
    "\\text{N}_{flops} &= \\sum_{k=0}^{n-2} \\sum_{i=k+1}^n \\sum_{j=k}^{n+1} (1) \\\\\n",
    "&\\approx \\sum_{k=1}^n \\sum_{i=k}^n (n-k) \\\\\n",
    "&\\approx \\sum_{k=1}^n (n-k)^2 =\\sum_{k=1}^n (n^2+k^2-2nk)\\\\\n",
    "&\\approx n^3+\\frac{n^3}{3}-2 n\\left(\\frac{n^2}{2}\\right)\\\\\n",
    "&= \\frac{n^3}{3}\n",
    "\\end{align}\n",
    "$$\n",
    "\n",
    "where the approximation is for large $n$.  The number of flops for back substitution is similarly calclulated\n",
    "\n",
    "$$\n",
    "\\begin{align}\n",
    "\\text{N}_{flops}&= \\sum_{k=n-1}^1 \\sum_{j=k+1}^n (1) \\\\\n",
    "&\\approx \\sum_{k=1}^n (n-k)\\\\\n",
    "&\\approx n^2-\\frac{n^2}{2} = \\frac{n^2}{2}\n",
    "\\end{align}\n",
    "$$\n",
    "\n",
    "We see that the work is dominated by the work of forward elimination ($\\sim n^3$ versus $\\sim n^2$ for back substitution).  You may wonder why we did not bother to include the cost of pivoting in the above calculations.  It is not too hard to show that the cost of partial pivoting scales like $n^2$, so is small compared to the overall cost of forward elmination for large $n$.  This assumes a comparison of two floating point operations takes a similar amount of time as 1 flop.  Total pivoting, however, scales with $n^3$ so adds to the cost of forward elimination substantially, which is why it is avoided unless absolutely necessary.\n",
    "\n",
    "The $n^3$ factor is a very daunting increase in cost as we increase the size of the system.  For example, calculated somewhat more precisely we have\n",
    "\n",
    "| $n$ | $N_{flops}$  |\n",
    "|-----|--------------|\n",
    "|  3  | $\\sim 170$   |\n",
    "| 10  | $\\sim 400$   |\n",
    "| 50  | $\\sim 44000$ |\n",
    "| 100 | $\\sim 340000$|\n",
    "\n",
    "The implications are such that if it took $1$ second to solve a system of size $n$ it would take close to $17$ minutes to solve a system $10$ times larger.  As a result, we will spend some time in the next few sections examining cases where we can lower that cost."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f47c2220-0914-4538-bde8-20c4456a57e8",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.20"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
